# 神经网络基础

## 1. 什么是神经网络？

神经网络（Neural Networks, NNs）是一种模仿人脑神经元网络结构的计算模型。它通过学习大量数据中的模式，来解决各种复杂问题，如图像识别、自然语言处理和预测分析。

可以把它想象成一个由许多相互连接的“神经元”组成的网络，每个连接都有一个“权重”，代表其重要性。

## 2. 神经元：网络的基本单元

每个神经元（或称为“节点”）是网络中最基本的处理单元。它接收来自其他神经元的输入，进行计算，然后将结果传递给下一个神经元。

一个神经元的工作流程如下：

1.  **接收输入**：接收多个输入值 (`x1, x2, ...`)。
2.  **加权求和**：每个输入都乘以一个对应的权重 (`w1, w2, ...`)，然后将所有加权后的输入相加，并加上一个偏置项 (`b`)。
    
    `z = (w1*x1 + w2*x2 + ...) + b`
    
3.  **激活函数**：将加权求和的结果 `z` 传入一个非线性的“激活函数” (`f`)，得到该神经元的最终输出。
    
    `output = f(z)`
    

权重和偏置是网络需要学习的参数。

## 3. 神经网络的结构：层

一个典型的神经网络由多个“层”组成：

*   **输入层 (Input Layer)**：接收原始数据。该层的神经元数量通常等于数据特征的数量（例如，如果要识别的图片是 28x28 像素，输入层可能有 784 个神经元）。
*   **隐藏层 (Hidden Layers)**：位于输入层和输出层之间，负责大部分的计算和特征提取。一个神经网络可以没有隐藏层，也可以有多个隐藏层。层数越多，网络越“深”。
*   **输出层 (Output Layer)**：产生最终的预测结果。输出层神经元的数量取决于具体的任务（例如，对于一个 10 分类问题，输出层通常有 10 个神经元）。

数据从输入层开始，依次通过一个或多个隐藏层，最后到达输出层，这个过程称为“前向传播”。

## 4. 网络的学习过程

神经网络通过一个称为“训练”的过程来学习。这个过程的目标是调整网络中的权重和偏置，使得网络的预测结果尽可能准确。

1.  **前向传播 (Forward Propagation)**：
    将一批训练数据输入网络，数据从输入层流向输出层，最终得到预测结果。

2.  **计算损失 (Loss Function)**：
    将网络的预测结果与真实的标签进行比较，通过一个“损失函数”（或“成本函数”）来计算它们之间的差距（即“损失”或“误差”）。损失越小，说明网络预测得越准。

3.  **反向传播 (Backpropagation)**：
    这是神经网络学习的核心算法。它会计算损失对每个权重和偏置的梯度（导数），这个梯度指明了如何调整参数才能使损失减小得最快。

4.  **更新参数 (Optimizer)**：
    根据反向传播计算出的梯度，使用一个优化器（如梯度下降法 Gradient Descent）来更新网络中所有的权重和偏置。

重复以上四个步骤，直到网络的损失足够小或达到预设的训练次数。

## 5. 常见的激活函数

激活函数为神经元引入了非线性能力，使得网络能够学习更复杂的模式。

*   **Sigmoid**：将输入压缩到 `(0, 1)` 之间。常用于二分类问题的输出层。
    `f(z) = 1 / (1 + e^-z)`
*   **ReLU (Rectified Linear Unit)**：目前最常用的激活函数之一。它计算简单，能有效缓解梯度消失问题。
    `f(z) = max(0, z)`
*   **Tanh (双曲正切)**：将输入压缩到 `(-1, 1)` 之间，可以看作是 Sigmoid 的一个变种。
    `f(z) = (e^z - e^-z) / (e^z + e^-z)`

## 6. 神经网络的种类

*   **前馈神经网络 (Feedforward Neural Network, FNN)**：最简单的类型，数据只能单向从输入层流向输出层。
*   **卷积神经网络 (Convolutional Neural Network, CNN)**：专门用于处理网格状数据，如图像。在图像识别、目标检测等领域非常成功。
*   **循环神经网络 (Recurrent Neural Network, RNN)**：专门用于处理序列数据，如文本或时间序列。网络中的连接可以形成环路，使其具有“记忆”能力。
